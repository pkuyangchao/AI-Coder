{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"数据导入\"\"\"\n",
    "\n",
    "import re\n",
    "filename =open('data0502.txt','r',encoding='utf-8')        #打开数据文件\n",
    "\n",
    "text = filename.read()        #将数据读取到字符串text中\n",
    "text = ' '.join(re.split(' |\\t|\\v',text))        #将数据中的空格符统一，便于后期处理(原始数据中空格符包含\\t、\\v等)   \n",
    "text = re.split('([: ,.\\n(){}\\[\\]=])',text)        #将字符串数据按照括号中的符号进行分割，分割成列表格式，并且在列表中保留分隔符\n",
    "\n",
    "text = list(filter(lambda x: x!=' 'and x!='',text))        #将列表中的空格和非空格筛选掉\n",
    "list_text = text        #保留一份列表格式的数据\n",
    "text = ' '.join(text)        #将列表转换成字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"文本词频统计\"\"\"\n",
    "\n",
    "def word_count(list_text):        #定义计算文本词频的函数，传入list_text列表\n",
    "    import collections\n",
    "    word_freq = collections.defaultdict(int)        #定义一个int型的词频词典，并提供默认值\n",
    "    for w in list_text:        #遍历列表中的元素，元素出现一次，频次加一\n",
    "        word_freq[w] += 1\n",
    "    return word_freq        #返回词频词典\n",
    "    \n",
    "    #return word_freq.items()   该语句返回值的类型为list（这句话有语法问题，不必考虑）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"根据text文本创建代码词词典\"\"\"\n",
    "\n",
    "def build_dict(text, min_word_freq=50):\n",
    "    word_freq = word_count(text)         #文本词频统计，返回一个词频词典\n",
    "    word_freq = filter(lambda x: x[1] > min_word_freq, word_freq.items())          # filter将词频数量低于指定值的代码词删除。\n",
    "    word_freq_sorted = sorted(word_freq, key=lambda x: (-x[1], x[0]))         # key用于指定排序的元素，因为sorted默认使用list中每个item的第一个元素从小到大排列，所以这里通过lambda进行前后元素调序，并对词频去相反数，从而将词频最大的排列在最前面\n",
    "    words, _ = list(zip(*word_freq_sorted))         #获取每一个代码词\n",
    "    word_idx = dict(zip(words, range(len(words))))         #构建词典（不包含词频）\n",
    "    word_idx['<unk>'] = len(words)         #unk表示unknown，未知单词\n",
    "    return words         #这里只返回了words，倒数两行代码还用不上。返回的是一个不含重复的代码词词典，不包含词频。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 104432\n",
      "Unique words: 5573\n",
      "Vectorization...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'说明一下，为什么要把x转换成向量形式、而非one-hot编码，而把y转换成one-hot\\nx之所以转换成向量形式，是为了便于将x输入到embedding层中。\\none-hot格式的x无法直接作为embedding层的输入（在我们这个模型中是不行的，其他模型就不一定了）。\\ny之所以转换成one-hot，是因为后面模型训练的时候，y必须是one-hot编码格式\\n其实全用one-hot编码也可以，只不过要转换格式才能导入到embedding层中，我觉得比较麻烦就没有这样做\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"数据预处理-字符串序列向量化\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "maxlen = 50         #提取50个代码词组成的序列\n",
    "step = 5         #每5个代码词采样一个新序列\n",
    "sentences = []         #保存所提取的序列\n",
    "next_words = []         #保存目标代码词\n",
    "\n",
    "cut_words = list_text         #将列表形式的元数据保存在cut_words中\n",
    "for i in range(0,len(cut_words) - maxlen,step):\n",
    "    sentences.append(cut_words[i:i + maxlen])         #将元数据按照步长来存储在每个序列中       \n",
    "    next_words.append(cut_words[i + maxlen])         #将目标代码词存储在next_words中\n",
    "    \n",
    "    \n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "\n",
    "words = list(build_dict(list_text,0))         #创建代码词词典，返回的是一个不含重复的代码词词典，不包含词频。\n",
    "print('Unique words:',len(words))\n",
    "#print(words)\n",
    "\n",
    "word_indices = dict((word,words.index(word)) for word in words)         #创建一个包含代码词唯一索引的代码词词典，返回的是一个字典\n",
    "#print(word_indices)\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences),maxlen))         #初始化x\n",
    "y = np.zeros((len(sentences)))         #初始化y\n",
    "for i,sentence in enumerate(sentences):\n",
    "    for t,word in enumerate(sentence):\n",
    "        x[i,t] = word_indices[word]         #将代码词转换成向量形式的编码\n",
    "    y[i] = word_indices[next_words[i]]\n",
    "\n",
    "y = keras.utils.to_categorical(y, len(words))         #将int型数组y转换成one-hot编码\n",
    "\n",
    "\"\"\"说明一下，为什么要把x转换成向量形式、而非one-hot编码，而把y转换成one-hot\n",
    "x之所以转换成向量形式，是为了便于将x输入到embedding层中。\n",
    "one-hot格式的x无法直接作为embedding层的输入（在我们这个模型中是不行的，其他模型就不一定了）。\n",
    "y之所以转换成one-hot，是因为后面模型训练的时候，y必须是one-hot编码格式\n",
    "其实全用one-hot编码也可以，只不过要转换格式才能导入到embedding层中，我觉得比较麻烦就没有这样做\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"定义下一个代码词的采样函数---temperature越大，代码生成的创造性越强---\"\"\"\n",
    "\n",
    "def sample(preds,temperature=0.1):         #《python深度学习》文本生成那一章介绍过temperature了，不明白的自行翻书\n",
    "    preds = np.asarray(preds).astype('float')\n",
    "    preds = np.log(preds) /temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1,preds,1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"将字符串写到指定文件中\"\"\"\n",
    "\n",
    "def save(filename, contents): \n",
    "      file = open(filename, 'a', encoding='utf-8')\n",
    "      file.write(contents)\n",
    "      file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"上面属于公共部分的代码，把它们提取出来了\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "----------------------------------------------------------------我是分割线------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"模型尝试一：yk_model_local_gpu-0507-01：Embedding + 单层LSTM(加入dropout)\"\"\"\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "def create_model(words):         #定义创建模型的函数\n",
    "    model = keras.models.Sequential()         #模型初始化\n",
    "    model.add(layers.Embedding(len(words),128))         #模型第一层为embedding层\n",
    "    model.add(layers.LSTM(128,dropout=0.2,recurrent_dropout=0.2))         #模型第二层为LSTM层，加入dropout减少过拟合\n",
    "    model.add(layers.Dense(len(words),activation='softmax'))         #模型第三层为全连接层\n",
    "\n",
    "    optimizer = keras.optimizers.RMSprop(lr=0.003)         #定义优化器\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=optimizer)         #模型编译\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         713344    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5573)              718917    \n",
      "=================================================================\n",
      "Total params: 1,563,845\n",
      "Trainable params: 1,563,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"创建模型实例\"\"\"\n",
    "model = create_model(words)         #创建模型\n",
    "model.summary()         #打印模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"模型保存\"\"\"\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath = \"yk_model_local_gpu-0507-01.hdf5\"         #尽量将模型名字和前面的标题统一，这样便于查找\n",
    "checkpoint = ModelCheckpoint(filepath, save_weights_only=False,verbose=1,save_best_only=False, period=1)         #回调函数，实现断点续训功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------epoch=5--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.5229Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 80s 766us/step - loss: 1.5232\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "from tensorflow.import keras\n",
      "import numpy as np\n",
      "from sklearn.metrics import preprocessing\n",
      "from keras.layers.core import Dense,Dropout,Activation\n",
      "from"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\01-software-installation\\06-python-3.5.4\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import BatchNormalization\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import BatchNormalization\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Dense\n",
      "from keras.layers.convolutional import BatchNormalization\n",
      "from keras.layers.convolutional import Conv1D\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "from tensorflow.keras import Sequential\n",
      "from keras.layers.core import Dense,Activation,Dropout,Activation\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import BatchNormalization\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import BatchNormalization\n",
      "from keras.layers.convolutional import BatchNormalization\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import BatchNormalization\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import BatchNormalization\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import BatchNormalization\n",
      "from keras.layers import LSTM\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "from tensorflow.keras import backend as K\n",
      "from tensorflow.python.keras import backend as K\n",
      "from tensorflow.python.keras import layers\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import BatchNormalization\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "\n",
      "---------------------------------------------------------epoch=6--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.5399Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 73s 700us/step - loss: 1.5398\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "return model\n",
      "def add():\n",
      "Dense = 1,activation =)\n",
      "return model\n",
      "def =():\n",
      "model = Sequential()\n",
      "model.add(Embedding())\n",
      "model.add(Dropout())\n",
      "model.add(Dense(1,activation =))\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def fit(self,epochs =,batch_size =,verbose =,validation_split =):\n",
      "self.model = Sequential()\n",
      "self.model.add(LSTM(256,return_sequences =,input_shape =()))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(64,activation =))\n",
      "self.model.add(Dense(units =,activation =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(256,activation =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(256,activation =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(LSTM(256,return_sequences =))\n",
      "model.add(LSTM(self.nb_classes,activation =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dropout())\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "return model\n",
      "def model():\n",
      "model = Sequential()\n",
      "model.add(Embedding())\n",
      "model.add(Dropout())\n",
      "model.add(Dense(1,activation =))\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def fit(self,batch_size =,epochs =,batch_size =,verbose =,dropout =,callbacks =,callbacks =,verbose =,mode =):\n",
      "model = Sequential()\n",
      "model.add(LSTM(64,return_sequences =,input_shape =()))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(1,activation =))\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def build_model():\n",
      "model = Sequential()\n",
      "model.add(Embedding())\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "return model\n",
      "def models():\n",
      "model = Sequential()\n",
      "model.add(Embedding())\n",
      "model.add(Dropout())\n",
      "model.add(Dense(1,activation =))\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def model():\n",
      "model = Sequential()\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "return model\n",
      "def __init__(self,callbacks =,nput_shape =():\n",
      "self.model = Sequential()\n",
      "self.model.add(LSTM(256,return_sequences =,input_shape =()))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(self.nb_classes,activation =))\n",
      "return model\n",
      "def __init__(self,input_dim =,dropout =):\n",
      "self.append()\n",
      "self.model = Sequential()\n",
      "self.model.add(Dense(128,activation =))\n",
      "self.model.add(Dense(self.nb_classes,activation =))\n",
      "self.model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def recurrent():\n",
      "def __init__():\n",
      "self.model = self.model.predict()\n",
      "self.return self.model.predict()\n",
      "def model():\n",
      "self.model = Sequential()\n",
      "self.model.add(Dense(64,activation =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(256,activation =))\n",
      "self.model.add(Dense(1,activation =))\n",
      "self.model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def models():\n",
      "self.model = Sequential()\n",
      "self.model.add(TimeDistributed(Dense(1,activation =))\n",
      "self.model.compile(loss =,optimizer =(lr =),metrics =[])\n",
      "return model\n",
      "\n",
      "---------------------------------------------------------epoch=7--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.5185Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 71s 684us/step - loss: 1.5191\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "model.add(Dense(1,activation =))\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def.():\n",
      "return model\n",
      "def __init__():\n",
      "self.model = self.fit(self.model.fit(x_train,y_train,epochs =,batch_size =,verbose =)\n",
      "def compile(optimizer =):\n",
      "return()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def __init__(self,callbacks =,validation_split =,verbose =):\n",
      "self.model = Sequential()\n",
      "self.model.add(LSTM(units =,input_shape =(),return_sequences =))\n",
      "self.model.add(Dense(self.compile())\n",
      "self.model = Sequential()\n",
      "self.model.add(LSTM(units =,return_sequences =,input_shape =()))\n",
      "self.model.add(LSTM())\n",
      "model.add(LSTM(self.nb_classes,activation =))\n",
      "self.model.compile(loss =,optimizer =(),metrics =[])\n",
      "self.model.fit(x_train,y_train,batch_size =,verbose =)\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def.():\n",
      "self.model = Sequential()\n",
      "self.model.add(LSTM(self.model.add(Dense(self.return self.model,input_shape =()))\n",
      "self.model = self.model.def input_shape():\n",
      "self.model = self.models = self.fit()\n",
      "def __init__(self,dropout:):from keras.layers.convolutional import Conv1D\n",
      "from keras.layers import LSTM\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers import Dense\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def import numpy as np\n",
      "import numpy as np\n",
      "import matplotlib\n",
      "import argparse\n",
      "import keras\n",
      "import csv\n",
      "from keras.layers import LSTM,Dense,Dropout,Activation,Flatten\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import LSTM\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers import Conv1D\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Conv1D,MaxPooling1D\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "from keras.callbacks import TensorBoard\n",
      "def __init__(self,output_dim =,callbacks =[-1]):\n",
      "self.model = Sequential()\n",
      "self.model.add(LSTM(16,input_shape =()))\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "model.add(Dense())\n",
      "return model\n",
      "def __init__():\n",
      "model = Sequential()\n",
      "model.add(LSTM(64,input_shape =(),return_sequences =))\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(Dense(256,activation =))\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from keras.regularizers import l2\n",
      "def build_model(top_words,embedding_vecor_length,max_review_length,show_summaries =):\n",
      "input_layer = Embedding(top_words,embedding_vecor_length,input_length =)\n",
      "branch_2 = Sequential()\n",
      "branch_3.add()\n",
      "branch_3.add(Conv1D(filters =,kernel_size =,padding =,kernel_regularizer =()))\n",
      "branch_5.add(Activation())\n",
      "branch_5.add(MaxPooling1D(pool_size =))\n",
      "branch_5.add(Dropout())\n",
      "branch_5.add(BatchNormalization())\n",
      "branch_5.add(Conv1D(filters =,kernel_size =,padding =,kernel_regularizer =()))\n",
      "branch_3.add(Activation())\n",
      "branch_3.add(MaxPooling1D(pool_size =))\n",
      "\n",
      "---------------------------------------------------------epoch=8--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.5059- Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 72s 693us/step - loss: 1.5058\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "X1 = np.array()\n",
      "model = Sequential()\n",
      "model.add(Embedding())\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =)\n",
      "return model\n",
      "def model():\n",
      "model = Sequential()\n",
      "model.add(Embedding())\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =)\n",
      "return model\n",
      "def import,():\n",
      "def __init__():\n",
      "self.model = Sequential()\n",
      "self.model.add(Dense(32,activation =))\n",
      "model.compile(loss =,optimizer =(),metrics =[])\n",
      "model.fit(X_train,y_train,batch_size =,nb_epoch =,batch_size =,epochs =,batch_size =,nb_epoch =,callbacks =[i])\n",
      "model.compile(loss =,optimizer =)\n",
      "return model\n",
      "def,():\n",
      "self.model = Sequential()\n",
      "self.model.add(Embedding(self.output,units =,return_sequences =,input_shape =(),units =,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =,input_shape =()))\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "X1 = np.array()\n",
      "()=()\n",
      "model = Sequential()\n",
      "model.add(Embedding())\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =)\n",
      "return model\n",
      "def():\n",
      "model = Sequential()\n",
      "model.add(Embedding())\n",
      "model.add(Dropout())\n",
      "model.add(LSTM())\n",
      "model.add(Dropout())\n",
      "model.add(Dense(1,activation =))\n",
      "model.compile(loss =,optimizer =)\n",
      "return model\n",
      "def import,():\n",
      "def __init__():\n",
      "self.model = Sequential()\n",
      "self.model.add(Embedding())\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(self.rnn_size,input_shape =(),units =,activation =))\n",
      "model.add(Dense(self.rnn_size,activation =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(self.rnn_size,activation =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(64,activation =))\n",
      "model.add(Dropout())\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "X1 = np.array()\n",
      "model = Sequential()\n",
      "model.add(Embedding())\n",
      "model.add(LSTM())\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =)\n",
      "return model\n",
      "def Dense():\n",
      "model = Sequential()\n",
      "model.add(Embedding())\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(input_shape =(),return_sequences =))\n",
      "model.add(LSTM())\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =)\n",
      "return model\n",
      "def,():\n",
      "def model():\n",
      "model = Sequential()\n",
      "model.add(Embedding(top_words,embedding_vecor_length,input_length =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM())\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =)\n",
      "\n",
      "---------------------------------------------------------epoch=9--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.4999Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 72s 692us/step - loss: 1.5000\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "history = model.predict()\n",
      "def.():\n",
      "self.model = self.input_shape =()\n",
      "self.model = Sequential()\n",
      "self.model.add(LSTM(units =,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(TimeDistributed(Dense()))\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def,recurrent_dropout =):\n",
      "self.model = Sequential()\n",
      "self.model.add(LSTM(units =,return_sequences =,input_shape =()))\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(64,activation =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def,():\n",
      "def __init__():\n",
      "self.model = self.if self.verbose from keras.callbacks import ModelCheckpoint\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "history = model.fit(X_train,y_train,batch_size =,verbose =,save_best_only =,mode =)\n",
      "model = Sequential()\n",
      "model.add(LSTM(256,return_sequences =,input_shape =()))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(64,return_sequences =))\n",
      "model.add(LSTM(64,input_shape =(),return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(1,activation =))\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def import numpy as np\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense,Dropout,Activation,Flatten\n",
      "from keras.layers.embeddings import Embedding\n",
      "from keras.layers import Embedding\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import LSTM\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers import LSTM\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "history = model.predict()\n",
      "return model\n",
      "def.():\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.X()\n",
      "def __init__():\n",
      "self.dropout = self.model.add(Bidirectional(LSTM(units =,return_sequences =,input_shape =(),units =,return_sequences =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(self.rnn_size,return_sequences =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(units =,activation =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(self.nb_classes,activation =))\n",
      "self.model = Sequential()\n",
      "self.model.add(Dense(self.rnn_size,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(TimeDistributed(Dense(units =)))\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def preprocessing():\n",
      "units = 3\n",
      "def __init__():\n",
      "self.dropout = self.input_shape\n",
      "self.model = self.model.add(Bidirectional(LSTM(Var.hidden_units,return_sequences =,activation =,name =,self.preprocessing =,tensorflow.keras.layers.Masking(Dense(self.rnn_size,input_shape =(),name =))()\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(TimeDistributed(Dense(units =,name =)))\n",
      "model.add(TimeDistributed(Conv2D(64,(),activation =)))\n",
      "\n",
      "---------------------------------------------------------epoch=10--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.4832Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 70s 672us/step - loss: 1.4828\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "plt.figure()\n",
      "plt.plot(history.history[],[],optimizer =,metrics =[])\n",
      "plt.plot(history.history[],epochs =,verbose =)\n",
      "plt.plot(history.history[],)\n",
      "plt.plot(history.history[],[],optimizer =,metrics =[])\n",
      "plt.plot(history.history[],)\n",
      "plt.plot(optimizer.array(),callbacks =[])\n",
      "plt.plot(history.history[],[],dropout =,return_sequences =)\n",
      "plt.plot(optimizer,loss =,dropout =)\n",
      "plt.plot(history.Embedding(input_dim =,output_dim =,input_length =,dropout =))\n",
      "plt.compile(loss =,optimizer =)\n",
      "return self.model.predict(np.reshape())\n",
      "def add():\n",
      "return self.model.predict()\n",
      "def __init__():\n",
      "self.model = Sequential()\n",
      "self.model.add(Embedding(256,input_dim =,input_length =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense())\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(units =,activation =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(256,activation =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(units =,activation =))\n",
      "self.model.compile(loss =,optimizer =,metrics =[])\n",
      "self.model.summary()\n",
      "def build_model():\n",
      "self.model.add(Dense())\n",
      "self.model.add(Dropout())\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "plt.figure()\n",
      "plt.plot(history.history[],)\n",
      "plt.plot(history.history[],)\n",
      "plt.plot(history.history[],)\n",
      "plt.plot(history.history[],[],epochs =,verbose =,mode =)\n",
      "plt.plot(history.history[],epochs =,verbose =)\n",
      "plt.plot(history.history[],optimizer =,dropout =[])\n",
      "plt.plot(history.history[],[],optimizer =,metrics =[])\n",
      "plt.plot(history.history[],)\n",
      "plt.plot(history.history[],[],optimizer =,dropout =[])\n",
      "plt.plot(history.history[],[],optimizer =,metrics =[])\n",
      "plt.plot(history.history[],)\n",
      "plt.plot(history.history[],epochs =,batch_size =,verbose =)\n",
      "plt.plot(history.history[],epochs =,verbose =)\n",
      "plt.plot(history.history[],)\n",
      "plt.plot(history.history[],[],optimizer =,dropout =[])\n",
      "plt.plot(history.history[],)\n",
      "plt.plot(history.history[],)\n",
      "plt.plot(history.history[],[],verbose =,return_sequences =)\n",
      "plt.plot(class Dense(),).callbacks.ModelCheckpoint(filepath =,verbose =,save_best_only =,mode =)\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "return model\n",
      "def model():\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "return model\n",
      "def\n",
      "import keras\n",
      "from keras.models import Sequential\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "plt.figure()\n",
      "plt.plot(class):\n",
      "def __init__():\n",
      "self.model = Sequential()\n",
      "self.model.add(Embedding(self.elif self.model.add(Bidirectional(LSTM(self.rnn_size,return_sequences =)))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(self.nb_classes,activation =))\n",
      "def build_model():\n",
      "self.model = Sequential()\n",
      "self.model.add(Embedding(input_dim =,output_dim =,return_sequences =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(LSTM(self.nb_classes,activation =))\n",
      "self.model.compile(loss =,optimizer =(),metrics =[])\n",
      "self.model.add(Activation())\n",
      "self.model.compile(loss =,optimizer =(),metrics =[])\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(64,activation =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(64,activation =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(units =,activation =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(units =,activation =))\n",
      "self.model.compile(loss =,optimizer =,metrics =[])\n",
      "self.model.fit(x_train,y_train,batch_size =,nb_epoch =,validation_data =())\n",
      "return model\n",
      "def model():\n",
      "self.model = Sequential()\n",
      "self.model.add(Embedding(units =,return_sequences =,self.add(Dropout()))\n",
      "self.model.add(Dense(output_dim =,activation =))\n",
      "\n",
      "---------------------------------------------------------epoch=11--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.4791Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 74s 706us/step - loss: 1.4794\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "test_input[c],,input_shape =())\n",
      "for i in range():\n",
      "return self.shape\n",
      "self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.fit(self.format(),validation_split =)\n",
      "def\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.lstm()\n",
      "self.model = self.return self.model\n",
      "def\n",
      "self.model = self.if self.model.model import keras\n",
      "self.fit()\n",
      "def Dense(self,batch_size =,nb_epoch =,batch_size =,validation_split =):\n",
      "self.input_shape =()\n",
      "self.model = self.lstm()\n",
      "def[]:\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.if self.reshape()\n",
      "self.model = self.input_shape =()\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "test_input[c],,input_shape =())\n",
      "for i in range():\n",
      "return self.model.predict()\n",
      "def add(Dense(self.nb_classes,activation =)):\n",
      "return self.model.predict()\n",
      "def add():\n",
      "return self.model\n",
      "def\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.__init__()\n",
      "self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.__init__()\n",
      "self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.elif self.:\n",
      "self.i = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.input_shape =()\n",
      "self.model = self.lstm()\n",
      "self.model = self.assertEqual()\n",
      "self.assertEqual()\n",
      "def\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "test_input[c],\n",
      "def Dense(self.nb_classes,activation =):\n",
      "return self.model\n",
      "def\n",
      "return()\n",
      "def LSTM(self,epochs =,batch_size =,validation_split =,validation_split =):\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import LSTM\n",
      "from keras.models import Sequential\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Activation\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Flatten\n",
      "from keras.layers import LSTM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Activation\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Flatten\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Activation\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Flatten\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Flatten\n",
      "\n",
      "---------------------------------------------------------epoch=12--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.4600Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 73s 696us/step - loss: 1.4604\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "model.reset_states()\n",
      "return model\n",
      "def Dense(self.nb_classes,activation =):\n",
      "return self.model.predict()\n",
      "def __init__(self,batch_size =,dropout =):\n",
      "self.model = self.lstm()\n",
      "elif model = =:\n",
      "self.model.save()\n",
      "def __init__():\n",
      "self.model = self.lstm()\n",
      "def layers(self.nb_classes,self.nb_classes,],self.nb_classes,self.if self.model.add(Dropout()))\n",
      "self.model.add(Dense(self.Dense(self.Dense(self.model.add(Activation())))\n",
      "self.model.compile(loss =,optimizer =,metrics =[])\n",
      "self.model.summary()\n",
      "def add(Dropout()):\n",
      "model.add(LSTM(self.,self.nb_classes,()))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense())\n",
      "self.model.add(Activation())\n",
      "self.model.compile(loss =,optimizer =(lr =),metrics =[])\n",
      "self.model.summary()\n",
      "def Dense(self.nb_classes,activation =):\n",
      "return self.model.fit(x_train,y_train,batch_size =,nb_epoch =,batch_size =,verbose =)\n",
      "def __init__(self,model =):\n",
      "self.model = self.lstm()\n",
      "def __init__(self,self.model =):\n",
      "self.model = self.lstm()\n",
      "elif model = =:\n",
      "self.model = self.lstm()\n",
      "elif model = =:\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "model.reset_states()\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def Dense(self.nb_classes,activation =):\n",
      "return self.model.predict()\n",
      "def Dense(self.nb_classes,activation =):\n",
      "return self.model.predict()\n",
      "def add():\n",
      "def __init__(self,seq_length =,self.nb_classes,]= self.nb_classes:\n",
      "self.model = self.lstm()\n",
      "def layers(self,loss =,dropout =):\n",
      "self.model = Sequential()\n",
      "self.model.add(Embedding(self.rnn_size,return_sequences =))\n",
      "model.add(LSTM(self.input_shape =()))\n",
      "model.add(Dense(self.nb_classes,activation =))\n",
      "return model\n",
      "def keras.backend():\n",
      "self.model = self.__init__()\n",
      "self.model = self.lstm()\n",
      "elif model = =:\n",
      "self.model = self.lstm()\n",
      "def layers(self,optimizer =,loss =):\n",
      "self.model = Sequential()\n",
      "self.model.add(Embedding(self.nb_classes,self.model.add(Dropout()))\n",
      "self.model.add(LSTM(self.rnn_size,return_sequences =))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(Conv3D(64,3,3,3,border_mode =,activation =,order_mode =,name =,name =,bsample =()))\n",
      "model.add(TimeDistributed(MaxPooling2D((),strides =(),strides =())))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(Conv2D(32,(),adding =,activation =)))\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "model.reset_states()\n",
      "return model\n",
      "def LSTM(self,model =):\n",
      "model = Sequential()\n",
      "model.add(Embedding(input_dim =,output_dim =,input_length =,name =))\n",
      "model.add(LSTM())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def Dense(self.nb_classes,activation =):\n",
      "return model\n",
      "def\n",
      "model = Sequential()\n",
      "model.add(LSTM(256,input_shape =()))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(64,activation =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "return model\n",
      "def\n",
      "model = Sequential()\n",
      "model.add(Embedding())\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def layers(name =):\n",
      "\n",
      "---------------------------------------------------------epoch=13--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.4378Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 72s 691us/step - loss: 1.4384\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "if remove_stopwords:\n",
      "model = Sequential()\n",
      "model.add(Embedding(top_words,embedding_vecor_length,input_length =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM())\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "model.fit(x_train,y_train,batch_size =,nb_epoch =,validation_split =)\n",
      "def random():\n",
      "return model\n",
      "def\n",
      "return()\n",
      "def Dense(self,Flatten,numpy as np\n",
      "return self.model.fit()\n",
      "def __init__():\n",
      "self.input_shape =()\n",
      "self.model = self.model.predict()\n",
      "def LSTM(self,input_shape =(),return_sequences =):\n",
      "model = keras.models.Sequential()\n",
      "self.model.add(Embedding(units =,units =,input_shape =()))\n",
      "for _ in range():\n",
      "model.add(keras.layers.LSTM())\n",
      "model.add(keras.layers.Bidirectional(LSTM()))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(self.nb_classes,activation =))\n",
      "return model\n",
      "def\n",
      "self.model = self.lstm()\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "if remove_stopwords:\n",
      "model = Sequential()\n",
      "model.add(Merge([model_language,model_image],mode =,concat_axis =))\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(units =,activation =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(units =,activation =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(1,activation =))\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "model.fit(x_train,y_train,batch_size =,epochs =,batch_size =,validation_split =)\n",
      "def __init__():\n",
      "self.model = Sequential()\n",
      "self.model.add(LSTM(units =,return_sequences =))\n",
      "model.add(TimeDistributed(Dense(units =)))\n",
      "self.model.compile(loss =,optimizer =,metrics =[])\n",
      "def):\n",
      "self.model = Sequential()\n",
      "self.model.add(TimeDistributed(Dense(units =,activation =)))\n",
      "self.model.compile(loss =,optimizer =,metrics =[])\n",
      "def):\n",
      "self.model = Sequential()\n",
      "self.model.add(Embedding(LSTM,return_sequences =,input_shape =()))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(units =,activation =))\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def,(self,batch_size =,nb_epoch =,validation_split =):\n",
      "self.model = Sequential()\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "if remove_stopwords:\n",
      "model = Sequential()\n",
      "model.add(LSTM(units =,return_sequences =,input_shape =()))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(32,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =,activation =))\n",
      "model.add(Dense(units =))\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "model.fit(x_train,y_train,batch_size =,nb_epoch =,batch_size =)\n",
      "return model\n",
      "def,():\n",
      "def __init__():\n",
      "self.input_shape =()\n",
      "self.model = self.reshape()\n",
      "self.model = self.model.predict()\n",
      "def LSTM(self,input_shape =(),return_sequences =):\n",
      "model = keras.models.Sequential()\n",
      "self.model.add(Embedding(units =,input_length =,dropout =,recurrent_dropout =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(units =))\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def =(self,batch_size =):\n",
      "self.model = self.import kernel_size\n",
      "self.input_shape =()\n",
      "self.model = self.lstm()\n",
      "def LSTM(self,input_shape =(),name =):\n",
      "\n",
      "---------------------------------------------------------epoch=14--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.4162Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 73s 701us/step - loss: 1.4168\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "from master import run_model,generate_read_me,get_text_data,load_word2vec\n",
      "import time\n",
      "import numpy as np\n",
      "import matplotlib\n",
      "import argparse\n",
      "import keras\n",
      "import csv\n",
      "from keras.datasets import imdb\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense,Dropout,Activation,Flatten,Embedding,LSTM,Bidirectional,LSTM,Activation,Flatten\n",
      "from keras.layers.embeddings import Embedding\n",
      "from keras.utils import plot_model\n",
      "import matplotlib.pyplot as plt\n",
      "from keras.regularizers import l2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def build_model(top_words,embedding_vecor_length,max_review_length,show_summaries =):\n",
      "input_layer = Embedding(top_words,embedding_vecor_length,input_length =)\n",
      "branch_2 = Sequential()\n",
      "branch_3 = Sequential()\n",
      "branch_3.add()\n",
      "branch_3.add(Conv1D(filters =,kernel_size =,padding =,kernel_regularizer =()))\n",
      "branch_3.add(Activation())\n",
      "branch_3.add(MaxPooling1D(pool_size =))\n",
      "branch_3.add(Dropout())\n",
      "branch_3.add(LSTM())\n",
      "branch_3 = Sequential()\n",
      "branch_3.add()\n",
      "branch_3.add(Conv1D(filters =,kernel_size =,padding =,kernel_regularizer =()))\n",
      "branch_3.add(Activation())\n",
      "branch_3.add(MaxPooling1D(pool_size =))\n",
      "branch_3.add(Dropout())\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "from master import run_model,generate_read_me,get_text_data,load_word2vec\n",
      "import time\n",
      "import numpy as np\n",
      "import matplotlib\n",
      "import argparse\n",
      "import keras\n",
      "import csv\n",
      "from keras.datasets import imdb\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense,Dropout,Activation,Flatten,Flatten,Embedding,LSTM,TimeDistributed,Activation,Conv1D,MaxPooling1D,LSTM,Bidirectional,LSTM,recurrent_dropout,return_sequences,Dropout,Flatten,Dense,Dropout,Activation,Flatten,Flatten,Flatten,LSTM,Dropout,Flatten,Flatten\n",
      "from keras.layers.embeddings import Embedding\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.embeddings import Embedding\n",
      "from keras.preprocessing import sequence\n",
      "from keras.utils import plot_model\n",
      "import matplotlib.pyplot as plt\n",
      "from keras.regularizers import l2\n",
      "def build_model(top_words,embedding_vecor_length,max_review_length,show_summaries =):\n",
      "input_layer = Embedding(top_words,embedding_vecor_length,input_length =)\n",
      "branch_2 = Sequential()\n",
      "branch_2.add()\n",
      "branch_2.add(Conv1D(filters =,kernel_size =,padding =,kernel_regularizer =()))\n",
      "branch_2.add(Activation())\n",
      "branch_2.add(MaxPooling1D(pool_size =))\n",
      "branch_2.add(Dropout())\n",
      "branch_2.add(LSTM())\n",
      "branch_2.add(Dropout())\n",
      "branch_2.add(LSTM())\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "from master import run_model,generate_read_me,get_text_data,load_word2vec\n",
      "import time\n",
      "import numpy as np\n",
      "import matplotlib\n",
      "import argparse\n",
      "import keras\n",
      "import csv\n",
      "from keras.datasets import imdb\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense,Dropout,Activation,Flatten,Embedding,LSTM,Flatten,Flatten\n",
      "from keras.layers.recurrent import LSTM\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.embeddings import Embedding\n",
      "from keras.preprocessing import sequence\n",
      "from keras.utils import plot_model\n",
      "import matplotlib.pyplot as plt\n",
      "from keras.regularizers import l2\n",
      "def build_model(top_words,embedding_vecor_length,max_review_length,show_summaries =):\n",
      "input_layer = Embedding(top_words,embedding_vecor_length,input_length =)\n",
      "branch_2 = Sequential()\n",
      "branch_2.add()\n",
      "branch_2.add(Conv1D(filters =,kernel_size =,padding =,kernel_regularizer =()))\n",
      "branch_2.add(Activation())\n",
      "branch_2.add(MaxPooling1D(pool_size =))\n",
      "branch_2.add(Dropout())\n",
      "branch_2.add(LSTM())\n",
      "branch_2.add(Dropout())\n",
      "branch_2.add(LSTM())\n",
      "branch_3 = Sequential()\n",
      "\n",
      "---------------------------------------------------------epoch=15--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.4091Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 73s 703us/step - loss: 1.4096\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "targ = targ[1].y[0]\n",
      "for i in range():\n",
      "for i in range():\n",
      "for i in range():\n",
      "for i in range(0,len():]\n",
      "self.model.add(Conv1D(filters =,kernel_size =,padding =,activation =,strides =,kernel_initializer =))\n",
      "model.add(keras.layers.LSTM(args.,return_sequences =,dropout =,recurrent_dropout =))\n",
      "if self.model = Sequential()\n",
      "model.add()\n",
      "self.model.add(Bidirectional(LSTM(256,return_sequences =,stateful =)))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(units =[-1]))\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def,units,Reshape =,input_shape =(),input_shape =(),return_sequences =):\n",
      "model = Sequential()\n",
      "model.add(LSTM(256,return_sequences =,input_shape =()))\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "if __name__ = =:\n",
      "return model\n",
      "def,outputs,batch_size =):\n",
      "return model\n",
      "def\n",
      "X = X[:,y = x[i],y,y = np.array()\n",
      "model = Sequential()\n",
      "model.add(LSTM(256,input_shape =(),return_sequences =))\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "targ = targ[1]\n",
      "if self.branch_6.add()\n",
      "branch_6.add(Dropout())\n",
      "branch_6.add(BatchNormalization())\n",
      "branch_6.add(LSTM())\n",
      "branch_6 = Sequential()\n",
      "branch_6.add()\n",
      "branch_6.add(Conv1D(filters =,kernel_size =,padding =,kernel_regularizer =()))\n",
      "branch_6.add(Activation())\n",
      "branch_6.add(MaxPooling1D(pool_size =))\n",
      "branch_6.add(Dropout())\n",
      "branch_6.add(BatchNormalization())\n",
      "branch_6.add(LSTM())\n",
      "branch_6 = Sequential()\n",
      "branch_6.add()\n",
      "branch_6.add(Conv1D(filters =,kernel_size =,padding =,kernel_regularizer =()))\n",
      "branch_6.add(Activation())\n",
      "branch_6.add(MaxPooling1D(pool_size =))\n",
      "branch_6.add(Dropout())\n",
      "branch_6.add(BatchNormalization())\n",
      "branch_6.add(BatchNormalization())\n",
      "branch_6.add(LSTM())\n",
      "branch_6 = Sequential()\n",
      "branch_6.add()\n",
      "branch_6.add(Conv1D(filters =,kernel_size =,padding =,kernel_regularizer =()))\n",
      "branch_6.add(Activation())\n",
      "branch_6.add(MaxPooling1D(pool_size =))\n",
      "branch_6.add(Dropout())\n",
      "branch_6.add(BatchNormalization())\n",
      "branch_6.add(LSTM())\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "targ = targ,y,epochs =,batch_size =)\n",
      "def model,axis =):\n",
      "model = Sequential()\n",
      "model.add(LSTM(256,input_shape =(),return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def,input_length =):\n",
      "model = Sequential()\n",
      "model.add(LSTM(64,input_shape =(),return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(256,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def,Input =(():,batch_size =,TimeDistributed =()))\n",
      "model_lstm.add(Dense())\n",
      "branch_3.add(Activation())\n",
      "branch_3.add(MaxPooling1D(pool_size =))\n",
      "branch_3.add(Dropout())\n",
      "branch_3.add(BatchNormalization())\n",
      "branch_3.add(LSTM())\n",
      "\n",
      "---------------------------------------------------------epoch=16--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.4082Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 73s 697us/step - loss: 1.4080\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "model.add(Embedding(input_dim =[0],output_dim =[1],return_sequences =))\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =))\n",
      "model.add(LSTM())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "model.fit(x_train,y_train,batch_size =,epochs =,batch_size =)\n",
      "return model\n",
      "def =():\n",
      "return self.model.predict()\n",
      "def __init__():\n",
      "return self.model.predict()\n",
      "def __init__():\n",
      "return self.model.predict()\n",
      "def __init__():\n",
      "return self.assertAllClose(keras.backend.eval(),np.ones(()))\n",
      "def __init__():\n",
      "self.input_shape =\n",
      "self.assertEqual()\n",
      "self.assertEqual()\n",
      "self.assertEqual()\n",
      "self.assertEqual()\n",
      "self.assertEqual()\n",
      "self.assertEqual()\n",
      "self.assertEqual()\n",
      "self.assertEqual()\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "model.add(Embedding())\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "model.fit(x_train,y_train,epochs =,batch_size =)\n",
      "model.save()\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense,Dropout,Activation\n",
      "from keras.layers.core import Reshape\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.embeddings import Embedding\n",
      "from keras.preprocessing import sequence\n",
      "from keras.utils import plot_model\n",
      "import matplotlib.pyplot as plt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from keras.regularizers import l2\n",
      "def build_model(top_words,embedding_vecor_length,max_review_length,show_summaries =):\n",
      "input_layer = Embedding(top_words,embedding_vecor_length,input_length =)\n",
      "branch_2 = Sequential()\n",
      "branch_2.add()\n",
      "branch_2.add(Conv1D(filters =,kernel_size =,padding =,kernel_regularizer =()))\n",
      "branch_2.add(Activation())\n",
      "branch_2.add(MaxPooling1D(pool_size =))\n",
      "branch_2.add(Dropout())\n",
      "branch_2.add(BatchNormalization())\n",
      "branch_2.add(LSTM())\n",
      "branch_2.add(Dropout())\n",
      "branch_2.add(LSTM())\n",
      "branch_2.add(Dropout())\n",
      "branch_2.add(LSTM())\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "model.add(LSTM(units,return_sequences =,input_shape =()))\n",
      "model.add(LSTM())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def add(Dense(1,activation =):):\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "model.fit(X_train,y_train,batch_size =,epochs =,batch_size =)\n",
      "model.save()\n",
      "def __init__():\n",
      "self.model = Sequential()\n",
      "self.model.add(Dense(self.branch_7.type =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(units =[-1]))\n",
      "if self.model.add(Activation())\n",
      "if self.model.add(Dropout())\n",
      "self.model.add(Dense(self.nb_classes,activation =))\n",
      "return model\n",
      "def =:\n",
      "self.model = self.model.predict()\n",
      "def layers.LSTM(optimizer,activation =):\n",
      "return self.model.predict()\n",
      "return self.model.predict()\n",
      "def __init__():\n",
      "self.input_shape =()\n",
      "self.assertEqual()\n",
      "self.assertEqual()\n",
      "self.assertEqual()\n",
      "self.assertEqual()\n",
      "\n",
      "---------------------------------------------------------epoch=17--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.3936Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 72s 688us/step - loss: 1.3937\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "from keras.layers import Dense,Dropout,Activation\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.embeddings import Embedding\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.embeddings import Embedding\n",
      "from keras.layers import Embedding\n",
      "from keras.layers import Embedding\n",
      "from keras.layers import LSTM,GRU,Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM,GRU,Dropout,Activation\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM,GRU,Bidirectional\n",
      "from keras.layers.recurrent import LSTM\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense,Dropout,Activation\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense,Dropout,Activation\n",
      "from keras.layers.recurrent import LSTM\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense,Dropout,Activation\n",
      "from keras.layers import LSTM\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.embeddings import Embedding\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import Dense,Dropout,Activation\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM,Dropout\n",
      "from keras.layers import LSTM,Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.embeddings import Embedding\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM,TimeDistributed\n",
      "from keras.layers.convolutional import Conv1D\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.embeddings import Embedding\n",
      "from keras.layers import LSTM\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "from keras.layers import Dense,Dropout,Activation\n",
      "from keras.layers import LSTM,Bidirectional\n",
      "from keras.layers import LSTM,Dropout,Activation\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import Dense,Dropout,Activation\n",
      "from keras.layers import LSTM,Dropout\n",
      "from keras.layers.recurrent import LSTM\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense,Dropout,Activation\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM,Flatten,Dropout,Activation\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM,GRU,Dropout,Activation\n",
      "from keras.layers import LSTM,Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.embeddings import Embedding\n",
      "from keras.layers import LSTM,Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.layers.embeddings import Embedding\n",
      "from keras.preprocessing import sequence\n",
      "from keras.utils import plot_model\n",
      "import matplotlib.pyplot as plt\n",
      "from keras.regularizers import l2\n",
      "def build_model(top_words,embedding_vecor_length,max_review_length,show_summaries =):\n",
      "input_layer = Embedding(top_words,embedding_vecor_length,input_length =)\n",
      "\n",
      "---------------------------------------------------------epoch=18--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.3855Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 77s 742us/step - loss: 1.3854\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "units = 3\n",
      "def,Dense,activation =):\n",
      "return np.ones(())\n",
      "self.assertEqual(len(),1)\n",
      "def,Input(shape =():\n",
      "self.assertEqual(len(),1)\n",
      "def model.recurrent()activation =,return_sequences =)\n",
      "return model\n",
      "def self.model.predict()\n",
      "def __init__():\n",
      "self.input_shape =()\n",
      "self.model = Sequential()\n",
      "self.model.add(LSTM(self.rnn_size,return_sequences =,activation =,input_shape =()))\n",
      "self.model.add(Dense(self.rnn_size,return_sequences =))\n",
      "model.add(TimeDistributed(MaxPooling2D((),strides =())))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(MaxPooling2D((),strides =())))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(Conv2D(32,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(MaxPooling2D((),strides =())))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(MaxPooling2D((),strides =())))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(MaxPooling2D((),strides =())))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(MaxPooling2D((),strides =())))\n",
      "model.add(TimeDistributed(Conv2D(32,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "units = 3\n",
      "def,Input =():\n",
      "Input = Sequential()\n",
      "model_language.add(LSTM(number_of_hidden_units_LSTM,return_sequences =,input_shape =()))\n",
      "model_language.add(LSTM(number_of_hidden_units_LSTM,return_sequences =))\n",
      "model_language.add(LSTM(number_of_hidden_units_LSTM,return_sequences =))\n",
      "model_language.add(LSTM(number_of_hidden_units_LSTM,return_sequences =))\n",
      "model_language.add(LSTM(number_of_hidden_units_LSTM,return_sequences =))\n",
      "model_language.add(LSTM(number_of_hidden_units_LSTM,return_sequences =))\n",
      "model = Sequential()\n",
      "model.add(Embedding(input_dim =,output_dim =,input_length =,name =))\n",
      "model.add(LSTM(LSTM())\n",
      "model.add(Dense(1,activation =))\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "if self.model = model:\n",
      "self.model = Sequential()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if self.model.add(Bidirectional(LSTM(units =,return_sequences =,dropout =,recurrent_dropout =)))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(self.rnn_size,1,activation =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(self.rnn_size,1,activation =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(self.nb_classes,activation =))\n",
      "return model\n",
      "def,(self,input_shape =():\n",
      "self.model = Sequential()\n",
      "self.model.add(Embedding(output_dim =[1],input_length =,dropout =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(1,activation =))\n",
      "self.model.compile(optimizer =,loss =,metrics =[])\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "units = 3\n",
      "def,Dense,activation =):\n",
      "model = Sequential()\n",
      "model.add(LSTM(32,return_sequences =,input_shape =()))\n",
      "model.add(LSTM(units =,return_sequences =,activation =,kernel_initializer =))\n",
      "model.add(LSTM(units =,return_sequences =,activation =,name =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(loss =,optimizer =,metrics =[]))\n",
      "return model\n",
      "def,():\n",
      "def __init__():\n",
      "model = Sequential()\n",
      "model.add(LSTM(units =,return_sequences =,input_shape =()))\n",
      "model.add(LSTM(units =,return_sequences =,activation =,kernel_initializer =))\n",
      "model.add(LSTM(self.rnn_size,return_sequences =))\n",
      "model.add(Bidirectional(LSTM(units =,return_sequences =,stateful =,return_sequences =))\n",
      "model.add(TimeDistributed(Dense(units =[-1])))\n",
      "else:\n",
      "model.add(Activation())\n",
      "model.add(MaxPooling2D(pool_size =(),strides =()))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(Conv2D(32,(),padding =,activation =)))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(Conv2D(32,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(Conv2D(32,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(Conv2D(64,(),adding =,activation =)))\n",
      "model.add(TimeDistributed(MaxPooling2D((),strides =())))\n",
      "\n",
      "---------------------------------------------------------epoch=19--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.3709Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 72s 685us/step - loss: 1.3706\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "if())\n",
      "if name = =:\n",
      "return model\n",
      "def):\n",
      "model = Sequential()\n",
      "model.add(Embedding(top_words,embedding_vecor_length,input_length =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "return model\n",
      "def,Dropout,add(LSTM():):\n",
      "model.add(Dense(1,activation =))\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def,():\n",
      "return model\n",
      "def,Conv1D(filters =,kernel_size =,padding =,activation =):\n",
      "model = Sequential()\n",
      "model.add(Embedding(input_dim =,output_dim =,input_length =,name =))\n",
      "model.add(LSTM(64,return_sequences =,input_shape =()))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(input_shape =()))\n",
      "model.add(Dense(units =,activation =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "return model\n",
      "def,Conv1D(filters =,kernel_size =,padding =,activation =):\n",
      "model = Sequential()\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "if()]\n",
      "else:\n",
      "if len()=()\n",
      "model = Sequential()\n",
      "model.add(Embedding(input_dim =,output_dim =,input_length =,weights =[x_test]))\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def,():\n",
      "def __init__():\n",
      "self.model = Sequential()\n",
      "self.model.add(LSTM(input_dim =,output_dim =,return_sequences =,nput_shape =(),name =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(units =,activation =))\n",
      "self.model.compile(loss =,optimizer =,metrics =[])\n",
      "self.model.summary()\n",
      "def):\n",
      "self.model = Sequential()\n",
      "self.model.add(Dense(units =,activation =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(Dense(units =,activation =))\n",
      "self.model.compile(loss =,optimizer =,metrics =[])\n",
      "self.model.summary()\n",
      "def,name =):\n",
      "self.model = Sequential()\n",
      "self.model.add(LSTM(self.rnn_size,return_sequences =))\n",
      "model.add(TimeDistributed(Dense(units =[-1])))\n",
      "else:\n",
      "model.add(keras_impl.layers.Bidirectional(keras_impl.layers.CuDNNLSTM(args.5,return_sequences =,kernel_initializer =)))\n",
      "else:\n",
      "model.add(keras_impl.layers.SimpleRNN(args[],return_sequences =,kernel_initializer =,dropout =[]))\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "if())\n",
      "if __name__ = =:\n",
      "return model\n",
      "def =:\n",
      "self.input_shape =()\n",
      "self.model = self.model\n",
      "self.input_shape =()\n",
      "self.model = self.model.predict()\n",
      "def __init__():\n",
      "self.input_shape =()\n",
      "self.model = self.tokenizer.texts_to_sequences()\n",
      "self.model = self.model.predict()\n",
      "def.shape():\n",
      "self.model = self.model.predict()\n",
      "def __init__():\n",
      "self.input_shape =()\n",
      "self.model = self.model\n",
      "self.input_shape =()\n",
      "self.model = self.lstm()\n",
      "def __init__():\n",
      "self.model = self.lstm()\n",
      "elif model = =:\n",
      "self.input_shape =()\n",
      "self.model = self.model.predict()\n",
      "def __init__():\n",
      "self.input_shape =()\n",
      "self.model = self.model\n",
      "self.input_shape =()\n",
      "self.model = self.model.predict()\n",
      "self.model = self.assertAllClose(keras.backend.backend(),initial_state =[0])\n",
      "\n",
      "---------------------------------------------------------epoch=20--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.3573Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 73s 697us/step - loss: 1.3571\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "return model\n",
      "def,Conv1D(Dropout,3,3,nb_classes,activation =,input_shape =()):\n",
      "return self.model.save()\n",
      "def __init__():\n",
      "self.model = Sequential()\n",
      "self.model.add(LSTM(units =,return_sequences =,input_shape =()))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(LSTM(units =,return_sequences =,activation =,name =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =,activation =,kernel_regularizer =()))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =,activation =,kernel_regularizer =()))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =,activation =,kernel_regularizer =()))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =,activation =,kernel_regularizer =()))\n",
      "model.add(LSTM(units =,return_sequences =,activation =))\n",
      "model.add(Dropout())\n",
      "model.add(Dense(units =[-1]))\n",
      "model.compile(loss =,optimizer =)\n",
      "return model\n",
      "def):\n",
      "self.model = Sequential()\n",
      "self.model.add(LSTM(input_dim =,output_dim =,return_sequences =))\n",
      "self.model.add(Dropout())\n",
      "self.model.add(LSTM(units =,return_sequences =,activation =,kernel_regularizer =()))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =,activation =,kernel_regularizer =()))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM(units =,return_sequences =,activation =,kernel_regularizer =()))\n",
      "model.add(Dropout())\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "return model\n",
      "def,Conv1D(top_words,embedding_vecor_length,3,padding =):\n",
      "model = Sequential()\n",
      "model.add(Embedding())\n",
      "model.add(Activation())\n",
      "model.add(Dropout())\n",
      "model.add(Dense(units =))\n",
      "model.add(Activation())\n",
      "model.add(Dropout())\n",
      "model.add(Dense(units =))\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def,Dropout():\n",
      "model = Sequential()\n",
      "model.add(Embedding(top_words,embedding_vecor_length,input_length =))\n",
      "model.add(LSTM())\n",
      "model.add(Dropout())\n",
      "model.add(Dense(units =))\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def,Conv1D(10,3,activation =):\n",
      "model = Sequential()\n",
      "model.add(Embedding(top_words,embedding_vecor_length,input_length =))\n",
      "model.add(LSTM())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def,Dropout():\n",
      "\n",
      "------ temperature: 0.8\n",
      "\n",
      "return model\n",
      "def,Conv1D(top_words,embedding_vecor_length,3,3,padding =):\n",
      "model = Sequential()\n",
      "model.add(Embedding())\n",
      "model.add(Activation())\n",
      "model.add(Dropout())\n",
      "model.add(Dense(units =))\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def):\n",
      "model = Sequential()\n",
      "model.add(Embedding(top_words,embedding_vecor_length,input_length =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM())\n",
      "model.add(Dense())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "return model\n",
      "def,Dropout():\n",
      "model = Sequential()\n",
      "model.add(Embedding(top_words,embedding_vecor_length,input_length =))\n",
      "model.add(LSTM())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "if show_summaries:\n",
      "return model\n",
      "os.environ[]=\n",
      "parser = argparse.ArgumentParser(description =)\n",
      "parser.add_argument(,action =,default =,help =)\n",
      "\n",
      "---------------------------------------------------------epoch=21--------------------------------------------------------------\n",
      "\n",
      "==============================正在从断点开始续训模型==============================\n",
      "Epoch 1/1\n",
      "104320/104432 [============================>.] - ETA: 0s - loss: 1.3493Epoch 00001: saving model to yk_model_local_gpu-0507-01.hdf5\n",
      "104432/104432 [==============================] - 73s 697us/step - loss: 1.3488\n",
      "\n",
      "------ temperature: 0.1\n",
      "\n",
      "model.compile(loss =,optimizer =)\n",
      "return model\n",
      "def model():\n",
      "model = Sequential()\n",
      "model.add(LSTM(input_shape =(),return_sequences =))\n",
      "model.add(LSTM())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "model.fit(X_train,y_train,batch_size =,epochs =)\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Dense,Dropout,Activation,Flatten,Flatten,Dropout,Flatten,MaxPooling1D,Flatten,Embedding,LSTM,Bidirectional\n",
      "from keras.models import Sequential\n",
      "from keras.layers import Embedding,LSTM,Dense\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers import Dropout\n",
      "from keras.layers import LSTM\n",
      "from keras.layers.convolutional import MaxPooling1D\n",
      "from keras.callbacks import TensorBoard\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "from keras.callbacks import TensorBoard\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "from keras.callbacks import TensorBoard\n",
      "from keras.callbacks import EarlyStopping\n",
      "from keras.layers import LSTM\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "from keras.callbacks import TensorBoard\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "\n",
      "------ temperature: 0.4\n",
      "\n",
      "model.compile(loss =,optimizer =)\n",
      "model.fit(X_train,y_train,batch_size =,epochs =)\n",
      "def if self.model:\n",
      "self.model = self.\n",
      "self.input_shape =()\n",
      "self.model = self.model\n",
      "self.input_shape =()\n",
      "self.model = self.predict()\n",
      "def __init__():\n",
      "self.model = self.layers\n",
      "self.input_shape =()\n",
      "self.model = self.model\n",
      "def = data():\n",
      "self.model = self.input_shape\n",
      "self.input_shape =()\n",
      "self.model = self.predict()\n",
      "self.model = self.assertAllClose(keras.backend.eval(),np.array(),np.))\n",
      "def model(0,1"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-51722ba0d5b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m                     \u001b[0msampled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                 \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m        \u001b[1;31m#预测并生成下一个代码词\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                 \u001b[0mnext_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemperature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mnext_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\01-software-installation\\06-python-3.5.4\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\01-software-installation\\06-python-3.5.4\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1781\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1782\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[1;32m-> 1783\u001b[1;33m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1784\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1785\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32md:\\01-software-installation\\06-python-3.5.4\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1297\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1299\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1300\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\01-software-installation\\06-python-3.5.4\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\01-software-installation\\06-python-3.5.4\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\01-software-installation\\06-python-3.5.4\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\01-software-installation\\06-python-3.5.4\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32md:\\01-software-installation\\06-python-3.5.4\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\01-software-installation\\06-python-3.5.4\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"训练模型\"\"\"\n",
    "\n",
    "#这一部分的代码我改的比较多，看的时候要稍微耐心点，有看不懂的地方可以随时问我\n",
    "\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "strings =''        #将生成的代码保存下来，一轮epoch结束后，将生成的代码写入到文件中\n",
    "\n",
    "#mark、last_word、start_gen定义的目的是为了让最终的生成的代码符合标准代码的格式要求----简言之就是该空格的地方空格，不该的就不空格\n",
    "mark = '.,()[]:{}\\n'        #将后面不需要空格的元素保存在字符串中\n",
    "last_word = ''\n",
    "start_gen=''\n",
    "\n",
    "for epoch in range(0,50):\n",
    "    print('\\n' + '---------------------------------------------------------epoch=' + str(epoch) + '--------------------------------------------------------------' + '\\n')\n",
    "    strings += '\\n' + '---------------------------------------------------------epoch=' + str(epoch) + '--------------------------------------------------------------' + '\\n'\n",
    "    \n",
    "    if os.path.exists(filepath):        #如果模型存在，则从现有模型开始训练\n",
    "        model.load_weights(filepath)\n",
    "        print(\"==============================正在从断点开始续训模型==============================\")\n",
    "        strings += \"==============================正在从断点开始续训模型==============================\"\n",
    "        \n",
    "        model.fit(x,y,batch_size=128,epochs=1,callbacks=[checkpoint])        #开始训练模型\n",
    "\n",
    "    else:\n",
    "        model.fit(x,y,batch_size=128,epochs=1,callbacks=[checkpoint])\n",
    "    \n",
    "    \n",
    "    for temperature in [0.1,0.4,0.8]:        #定义随时数，随机数越高，文本生成的创造性越强，规则表示越弱\n",
    "        print('\\n' + '------ temperature:' ,str(temperature) +'\\n' )\n",
    "        strings += '\\n' + '------ temperature:' + str(temperature) +'\\n' \n",
    "        \n",
    "        for j in range(30):       #生成30行代码\n",
    "            if temperature == 0.1:        #随机选择起始代码序列\n",
    "                if j == 0:\n",
    "                    start_index = random.randint(0,len(cut_words) - step - 1)        #随机选择一个代码序列作为代码生成的开头，这个随机序列必须位于某一个代码句的开头\n",
    "                    while cut_words[start_index] != '\\n':        #如果起始代码词不是换行符，则选择下一个代码词\n",
    "                        start_index += 1\n",
    "                        if start_index >= (len(cut_words) - step - 1):       #如果起始代码词的下标超过了最大长度，重新随机一个起始位置\n",
    "                            start_index = random.randint(0,len(cut_words) - step - 1)\n",
    "\n",
    "                    generated_text = cut_words[start_index + 1:start_index + 1 + step]        #选择起始代码序列（一个步长）\n",
    "                    start_gen = generated_text[:]        #将起始代码序列保存在start_gen中\n",
    "                    \n",
    "                    for k in range(len(generated_text)):        #将生成的代码转换成标准代码格式，并打印出来\n",
    "                        if generated_text[k] not in mark and last_word not in mark:\n",
    "                            sys.stdout.write(' ' + generated_text[k])\n",
    "                            strings += ' ' + generated_text[k]\n",
    "                        else:\n",
    "                            sys.stdout.write(generated_text[k])\n",
    "                            strings += generated_text[k]\n",
    "                        last_word = generated_text[k]\n",
    "            else:\n",
    "                if j == 0:\n",
    "                    generated_text = start_gen[:]        #若temperature不等于0.1，则让别的temperature的初始序列和0.1的一样\n",
    "                    last_word = ''\n",
    "                    for k in range(len(generated_text)):        #将生成的代码转换成标准代码格式，并打印出来\n",
    "                            if generated_text[k] not in mark and last_word not in mark:\n",
    "                                sys.stdout.write(' ' + generated_text[k])\n",
    "                                strings += ' ' + generated_text[k]\n",
    "                            else:\n",
    "                                sys.stdout.write(generated_text[k])\n",
    "                                strings += generated_text[k]\n",
    "                            last_word = generated_text[k]\n",
    "                    \n",
    "            for i in range(50):        #生成一个代码句\n",
    "                sampled = np.zeros((1,len(generated_text)))        #根据现有代码词长度，初始化一个相同长度的sampled\n",
    "                for t,word in enumerate(generated_text):        #将已有代码词向量化\n",
    "                    sampled[0,t] = word_indices[word]\n",
    "\n",
    "                preds = model.predict(sampled,verbose=0)[0]        #预测并生成下一个代码词\n",
    "                next_index = sample(preds,temperature = 0.3)\n",
    "                next_word = words[next_index]\n",
    "\n",
    "\n",
    "                generated_text.append(next_word)        #将生成的代码词加到已生成的代码序列中\n",
    "                \n",
    "                #如果下面这两句话不标注掉，那么本模型是按照滑动框（n-gram）来训练的。标注掉以后，每一个新的代码词都是从已生成的代码序列来进行预测的。\n",
    "                #if len(generated_text) == maxlen: \n",
    "                #    generated_text = generated_text[1:]\n",
    "\n",
    "                if next_word not in mark and last_word not in mark:        #将生成的代码转换成标准代码格式，并打印出来\n",
    "                    sys.stdout.write(' ' + next_word)\n",
    "                    strings += ' ' + next_word\n",
    "                else:\n",
    "                    sys.stdout.write(next_word)\n",
    "                    strings +=  next_word\n",
    "                \n",
    "                last_word = next_word\n",
    "    \n",
    "                if next_word == '\\n':        #如果预测的代码词为\\n，那么表示这一句结束\n",
    "                    break\n",
    "            \n",
    "            last_word = ''\n",
    "                \n",
    "        save('model_training_result/yk_model_local_gpu-0507-01.hdf5.txt',strings)        #将生成的代码保存\n",
    "        strings = ''\n",
    "        generated_text = ''\n",
    "    start_gen=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"开始测试\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"定义测试函数--代码句推荐\"\"\"\n",
    "\n",
    "def generate_text_sentence(seed_text,model_filename):        #测试代码和上面训练模型的代码基本一样，就不再介绍\n",
    "    model.load_weights(model_filename)\n",
    "    \n",
    "    strings=''\n",
    "    last_word=''\n",
    "    seed_text = re.split('([: ,.\\n(){}\\[\\]=])',seed_text)\n",
    "    seed_text = list(filter(lambda x: x!=' 'and x!='',seed_text))\n",
    "    \n",
    "    generated_text = seed_text[:]\n",
    "    \n",
    "    for temperature in [0.1,0.4,0.8]:\n",
    "        strings += '\\n' + '-------------temperature:' + str(temperature) +'-------------\\n' +'\\n'\n",
    "        \n",
    "        for i in range(50):\n",
    "            if i == 0:\n",
    "                for k in range(len(generated_text)):\n",
    "                    if generated_text[k] not in mark and last_word not in mark:\n",
    "                        strings += ' ' + generated_text[k]\n",
    "                    else:\n",
    "                        strings += generated_text[k]\n",
    "                    last_word = generated_text[k]\n",
    "\n",
    "            sampled = np.zeros((1,len(generated_text)))\n",
    "            for t,word in enumerate(generated_text):\n",
    "                sampled[0,t] = word_indices[word]\n",
    "\n",
    "            preds = model.predict(sampled,verbose=0)[0]\n",
    "            next_index = sample(preds,temperature = 0.3)\n",
    "            next_word = words[next_index]\n",
    "\n",
    "\n",
    "            generated_text.append(next_word)\n",
    "\n",
    "            #if len(generated_text) == maxlen:\n",
    "            #    generated_text = generated_text[1:]\n",
    "\n",
    "            if next_word not in mark and last_word not in mark:\n",
    "                strings += ' ' + next_word\n",
    "            else:\n",
    "                strings +=  next_word\n",
    "\n",
    "            last_word = next_word\n",
    "\n",
    "            if next_word == '\\n':\n",
    "                break\n",
    "        \n",
    "        generated_text = seed_text[:]\n",
    "        \n",
    "    return strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"定义测试函数--代码段推荐\"\"\"\n",
    "\n",
    "def generate_text_paragraph(seed_text,model_filename):        #测试代码和上面训练模型的代码基本一样，就不再介绍\n",
    "    model.load_weights(model_filename)\n",
    "    \n",
    "    strings=''\n",
    "    seed_text = re.split('([: ,.\\n(){}\\[\\]=])',seed_text)\n",
    "    seed_text = list(filter(lambda x: x!=' 'and x!='',seed_text))\n",
    "    \n",
    "    for temperature in [0.1,0.4,0.8]:\n",
    "        strings += '\\n' + '-------------temperature:' + str(temperature) +'-------------\\n' +'\\n'\n",
    "        \n",
    "        for i in range(10):\n",
    "            if i == 0:\n",
    "                last_word=''\n",
    "                generated_text = seed_text[:]\n",
    "                for k in range(len(generated_text)):\n",
    "                    if generated_text[k] not in mark and last_word not in mark:\n",
    "                        strings += ' ' + generated_text[k]\n",
    "                    else:\n",
    "                        strings += generated_text[k]\n",
    "                    last_word = generated_text[k]            \n",
    "                        \n",
    "            for j in range(30):\n",
    "                sampled = np.zeros((1,len(generated_text)))\n",
    "                for t,word in enumerate(generated_text):\n",
    "                    sampled[0,t] = word_indices[word]\n",
    "\n",
    "                preds = model.predict(sampled,verbose=0)[0]\n",
    "                next_index = sample(preds,temperature = 0.3)\n",
    "                next_word = words[next_index]\n",
    "\n",
    "\n",
    "                generated_text.append(next_word)\n",
    "\n",
    "                #if len(generated_text) == maxlen:\n",
    "                #    generated_text = generated_text[1:]\n",
    "\n",
    "                if next_word not in mark and last_word not in mark:\n",
    "                    strings += ' ' + next_word\n",
    "                else:\n",
    "                    strings +=  next_word\n",
    "\n",
    "                last_word = next_word\n",
    "\n",
    "                if next_word == '\\n':\n",
    "                    break\n",
    "        \n",
    "    return strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入代码词：def model()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\01-software-installation\\06-python-3.5.4\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------temperature:0.1-------------\n",
      "\n",
      "def model():\n",
      "model = Sequential()\n",
      "model.add(LSTM(input_shape =(),return_sequences =))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM())\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "model.fit(x_train,y_train,batch_size =,epochs =,validation_split =)\n",
      "\n",
      "-------------temperature:0.4-------------\n",
      "\n",
      "def model():\n",
      "model = Sequential()\n",
      "model.add(LSTM(input_shape =(),return_sequences =))\n",
      "model.add(LSTM())\n",
      "model.add(Dropout())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "model.fit(X_train,y_train,batch_size =,nb_epoch =,validation_split =)\n",
      "from keras.models import Sequential\n",
      "\n",
      "-------------temperature:0.8-------------\n",
      "\n",
      "def model():\n",
      "model = Sequential()\n",
      "model.add(LSTM(32,return_sequences =,input_shape =()))\n",
      "model.add(Dropout())\n",
      "model.add(LSTM())\n",
      "model.add(Dense())\n",
      "model.add(Activation())\n",
      "model.compile(loss =,optimizer =,metrics =[])\n",
      "model.fit(X_train,y_train,batch_size =,nb_epoch =,validation_split =)\n",
      "def import LSTM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"进行测试\"\"\"\n",
    "\n",
    "input_strings = input(\"请输入代码词：\")\n",
    "model_filename = 'yk_model_local_gpu-0507-01.hdf5'\n",
    "strings = generate_text_paragraph(input_strings,model_filename)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
